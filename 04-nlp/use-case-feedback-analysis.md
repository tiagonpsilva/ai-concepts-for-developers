# üìä Caso de Uso: Sistema de An√°lise de Feedback de Usu√°rios

## üéØ Objetivo

Desenvolver um sistema de an√°lise de feedback baseado em NLP capaz de processar e extrair insights valiosos de grandes volumes de coment√°rios, avalia√ß√µes e feedback de usu√°rios, permitindo que as empresas identifiquem padr√µes, problemas e oportunidades de melhoria em seus produtos e servi√ßos.

## üîç Problema de Neg√≥cio

As empresas enfrentam desafios significativos ao lidar com feedback de usu√°rios:

- Volume massivo de coment√°rios em m√∫ltiplos canais
- Dificuldade em identificar tend√™ncias e padr√µes manualmente
- Atraso entre o recebimento do feedback e a implementa√ß√£o de melhorias
- Inconsist√™ncia na categoriza√ß√£o e prioriza√ß√£o de problemas
- Necessidade de contextualiza√ß√£o para tomada de decis√£o

Um sistema de an√°lise de feedback baseado em NLP pode transformar dados n√£o estruturados em insights acion√°veis, identificando problemas emergentes, rastreando sentimentos dos clientes e informando decis√µes estrat√©gicas em tempo quase real.

## üìä Dados Necess√°rios

- Avalia√ß√µes e coment√°rios de usu√°rios de produtos/servi√ßos
- Feedback de atendimento ao cliente
- Men√ß√µes em m√≠dias sociais e f√≥runs
- Respostas a pesquisas de satisfa√ß√£o
- Dados de contexto (vers√£o do produto, segmento do cliente, data)

## üõ†Ô∏è Arquitetura do Sistema

```mermaid
graph TD
    A[Coleta de Feedback] --> A1[APIs]
    A --> A2[Web Scraping]
    A --> A3[Formul√°rios/Surveys]
    A --> A4[Email/SMS]
    
    A1 --> B[ETL e Armazenamento]
    A2 --> B
    A3 --> B
    A4 --> B
    
    B --> C[Pr√©-processamento]
    C --> D[Pipeline NLP]
    
    D --> D1[An√°lise de Sentimento]
    D --> D2[Classifica√ß√£o de T√≥picos]
    D --> D3[Extra√ß√£o de Entidades]
    D --> D4[Detec√ß√£o de Inten√ß√£o]
    
    D1 --> E[Agrega√ß√£o de Insights]
    D2 --> E
    D3 --> E
    D4 --> E
    
    E --> F[Visualiza√ß√£o e Relat√≥rios]
    E --> G[Alertas e Notifica√ß√µes]
    E --> H[API de Insights]
```

### 1. Componentes Principais

#### Pipeline de Processamento NLP

```mermaid
graph LR
    A[Texto Bruto] --> B[Limpeza e Normaliza√ß√£o]
    B --> C[Tokeniza√ß√£o]
    C --> D[Remo√ß√£o de Stopwords]
    D --> E[An√°lise de Sentimento]
    D --> F[Classifica√ß√£o de T√≥picos]
    D --> G[Extra√ß√£o de Entidades]
    E & F & G --> H[Agrega√ß√£o de Resultados]
```

#### An√°lise de Sentimento Multin√≠vel

```mermaid
graph TD
    A[Feedback Completo] --> B[Sentimento Global]
    A --> C[Sentimento por Aspecto]
    A --> D[An√°lise de Emo√ß√µes]
    
    C --> C1[UI/UX]
    C --> C2[Performance]
    C --> C3[Pre√ßo]
    C --> C4[Suporte]
    
    D --> D1[Satisfa√ß√£o]
    D --> D2[Frustra√ß√£o]
    D --> D3[Surpresa]
    D --> D4[Confian√ßa]
```

### 2. T√©cnicas de NLP Aplicadas

#### Classifica√ß√£o de T√≥picos

Identificar os principais assuntos mencionados no feedback:

- **Modelos supervisionados**: Classifica√ß√£o em categorias predefinidas
- **Modelagem de T√≥picos (LDA, NMF)**: Descoberta n√£o supervisionada de temas
- **Transformers Fine-tuned**: Para classifica√ß√£o multi-label com contexto

#### An√°lise de Sentimento

Determinar a polaridade e intensidade emocional do feedback:

- **Lexicon-based**: Utilizando dicion√°rios de palavras com pontua√ß√µes de sentimento
- **Modelos de Machine Learning**: SVM, Naive Bayes para classifica√ß√£o simples
- **Deep Learning**: BERT, RoBERTa para an√°lise contextual e nuances

#### Named Entity Recognition (NER)

Extrair men√ß√µes espec√≠ficas a produtos, recursos, pessoas ou eventos:

- **Modelos CRF/BiLSTM**: Para entidades padr√£o
- **BERT-NER customizado**: Para entidades espec√≠ficas do dom√≠nio
- **Few-shot learning**: Para adapta√ß√£o r√°pida a novos tipos de entidades

## üíª Exemplo de Implementa√ß√£o

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# NLP Libraries
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import spacy
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import torch

# Carregar dataset de exemplo (avalia√ß√µes de produtos)
df = pd.read_csv('product_reviews.csv')
print(f"Total de avalia√ß√µes: {len(df)}")

# Pr√©-processamento de texto
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

stop_words = set(stopwords.words('portuguese'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    if isinstance(text, str):
        # Tokeniza√ß√£o
        tokens = word_tokenize(text.lower())
        # Remover stopwords e pontua√ß√£o
        tokens = [t for t in tokens if t.isalpha() and t not in stop_words]
        # Lemmatiza√ß√£o
        tokens = [lemmatizer.lemmatize(t) for t in tokens]
        return ' '.join(tokens)
    return ''

# Aplicar pr√©-processamento
df['processed_text'] = df['review_text'].apply(preprocess_text)

# Carregando modelos pr√©-treinados para an√°lise de sentimento
sentiment_model_name = "neuralmind/bert-base-portuguese-cased"
tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=3)  # Positivo, Neutro, Negativo

# Configurar pipeline de an√°lise de sentimento
sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model=model,
    tokenizer=tokenizer,
    return_all_scores=True
)

# Fun√ß√£o para an√°lise de sentimento
def analyze_sentiment(text):
    if not text or not isinstance(text, str):
        return {"positive": 0, "neutral": 0.5, "negative": 0.5}
    
    try:
        result = sentiment_analyzer(text)
        scores = result[0]
        return {score['label']: score['score'] for score in scores}
    except Exception as e:
        print(f"Erro na an√°lise de sentimento: {e}")
        return {"positive": 0, "neutral": 0.5, "negative": 0.5}

# Aplicar an√°lise de sentimento (em amostra para demonstra√ß√£o)
sample_size = min(1000, len(df))
df_sample = df.sample(sample_size, random_state=42)
sentiments = df_sample['processed_text'].apply(analyze_sentiment)

# Extrair scores para an√°lise
df_sample['sentiment_positive'] = sentiments.apply(lambda x: x.get('positive', 0))
df_sample['sentiment_neutral'] = sentiments.apply(lambda x: x.get('neutral', 0))
df_sample['sentiment_negative'] = sentiments.apply(lambda x: x.get('negative', 0))
df_sample['sentiment_label'] = df_sample[['sentiment_positive', 'sentiment_neutral', 'sentiment_negative']].idxmax(axis=1).apply(lambda x: x.replace('sentiment_', ''))

# Modelagem de t√≥picos usando LDA
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# Preparar vectorizer
vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=1000)
X = vectorizer.fit_transform(df_sample['processed_text'])

# Treinar modelo LDA
n_topics = 5
lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)
lda.fit(X)

# Fun√ß√£o para exibir os principais termos por t√≥pico
def display_topics(model, feature_names, n_top_words):
    topics = {}
    for topic_idx, topic in enumerate(model.components_):
        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]
        topics[f"Topic {topic_idx+1}"] = top_words
    return topics

# Extrair os principais termos por t√≥pico
feature_names = vectorizer.get_feature_names_out()
topics = display_topics(lda, feature_names, 10)

# Atribuir t√≥picos aos documentos
topic_assignments = lda.transform(X)
df_sample['primary_topic'] = np.argmax(topic_assignments, axis=1) + 1

# Extrair entidades nomeadas usando spaCy
nlp = spacy.load('pt_core_news_sm')

def extract_entities(text):
    if not isinstance(text, str) or not text:
        return []
    
    doc = nlp(text)
    entities = []
    for ent in doc.ents:
        entities.append({
            'text': ent.text,
            'label': ent.label_,
            'start': ent.start_char,
            'end': ent.end_char
        })
    return entities

# Aplicar extra√ß√£o de entidades (amostra para demonstra√ß√£o)
small_sample = df_sample.head(100)
small_sample['entities'] = small_sample['review_text'].apply(extract_entities)

# Agrega√ß√£o e an√°lise explorat√≥ria
topic_sentiment = df_sample.groupby('primary_topic')['sentiment_label'].value_counts().unstack().fillna(0)
topic_sentiment_pct = topic_sentiment.div(topic_sentiment.sum(axis=1), axis=0) * 100

# An√°lise de tend√™ncias temporais
if 'review_date' in df_sample.columns:
    df_sample['review_date'] = pd.to_datetime(df_sample['review_date'])
    df_sample['month_year'] = df_sample['review_date'].dt.to_period('M')
    temporal_sentiment = df_sample.groupby('month_year')['sentiment_label'].value_counts().unstack().fillna(0)
    
    # C√°lculo de Net Promoter Score (NPS) ao longo do tempo
    def classify_sentiment(row):
        if row['sentiment_positive'] > 0.6:
            return 'Promoter'
        elif row['sentiment_negative'] > 0.6:
            return 'Detractor'
        else:
            return 'Passive'
    
    df_sample['nps_category'] = df_sample.apply(classify_sentiment, axis=1)
    nps_over_time = df_sample.groupby('month_year')['nps_category'].value_counts().unstack().fillna(0)
    
    # C√°lculo do NPS
    nps_over_time['NPS'] = ((nps_over_time['Promoter'] - nps_over_time['Detractor']) / 
                            (nps_over_time['Promoter'] + nps_over_time['Passive'] + nps_over_time['Detractor'])) * 100

# An√°lise de co-ocorr√™ncia de t√≥picos e entidades
if 'entities' in small_sample.columns:
    entity_topic_cooccurrence = pd.DataFrame()
    for idx, row in small_sample.iterrows():
        for entity in row['entities']:
            entity_topic_cooccurrence = entity_topic_cooccurrence.append({
                'topic': row['primary_topic'],
                'entity_text': entity['text'],
                'entity_type': entity['label'],
                'sentiment': row['sentiment_label']
            }, ignore_index=True)
    
    # An√°lise de entidades mais mencionadas por t√≥pico
    entity_counts = entity_topic_cooccurrence.groupby(['topic', 'entity_text']).size().reset_index(name='count')
    top_entities_per_topic = entity_counts.sort_values(['topic', 'count'], ascending=[True, False]).groupby('topic').head(5)

# Dashboard para visualiza√ß√£o (exemplo simplificado)
def create_dashboard():
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # Distribui√ß√£o geral de sentimentos
    sentiment_counts = df_sample['sentiment_label'].value_counts()
    axes[0, 0].pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90)
    axes[0, 0].set_title('Distribui√ß√£o de Sentimentos')
    
    # Sentimento por t√≥pico
    topic_sentiment_pct.plot(kind='bar', stacked=True, ax=axes[0, 1])
    axes[0, 1].set_title('Sentimento por T√≥pico')
    axes[0, 1].set_ylabel('Porcentagem')
    
    # Palavras mais comuns por t√≥pico
    topic_idx = 1  # Escolher um t√≥pico para visualizar
    topic_words = topics[f"Topic {topic_idx}"]
    axes[1, 0].barh(range(len(topic_words)), [1] * len(topic_words))
    axes[1, 0].set_yticks(range(len(topic_words)))
    axes[1, 0].set_yticklabels(topic_words)
    axes[1, 0].set_title(f'Palavras Principais - T√≥pico {topic_idx}')
    
    # Evolu√ß√£o temporal do sentimento (se dispon√≠vel)
    if 'temporal_sentiment' in locals():
        temporal_sentiment.plot(ax=axes[1, 1])
        axes[1, 1].set_title('Evolu√ß√£o do Sentimento ao Longo do Tempo')
        axes[1, 1].set_ylabel('N√∫mero de Reviews')
    
    plt.tight_layout()
    plt.savefig('feedback_dashboard.png')
    plt.close()

# Implementa√ß√£o de alertas autom√°ticos
def generate_alerts(df, threshold=0.7):
    alerts = []
    
    # Alerta para aumento significativo de sentimento negativo
    recent_data = df[df['review_date'] >= (df['review_date'].max() - pd.Timedelta(days=7))]
    if recent_data['sentiment_negative'].mean() > threshold:
        topics = recent_data[recent_data['sentiment_label'] == 'negative']['primary_topic'].value_counts().index[0]
        alerts.append({
            'type': 'HIGH_NEGATIVE_SENTIMENT',
            'description': f'Aumento significativo de sentimento negativo detectado nos √∫ltimos 7 dias, principalmente relacionado ao T√≥pico {topics}',
            'severity': 'HIGH'
        })
    
    # Alerta para t√≥picos emergentes
    topic_growth = df.groupby(['month_year', 'primary_topic']).size().unstack().fillna(0).pct_change().iloc[-1]
    growing_topics = topic_growth[topic_growth > 0.3].index.tolist()
    
    if growing_topics:
        for topic in growing_topics:
            alerts.append({
                'type': 'EMERGING_TOPIC',
                'description': f'Crescimento r√°pido detectado no T√≥pico {topic}',
                'severity': 'MEDIUM'
            })
    
    return alerts

# Exemplo de uso do sistema completo
def main():
    # Pr√©-processar dados
    preprocessed_data = preprocess_feedback_data()
    
    # Analisar sentimentos
    sentiment_results = analyze_sentiments(preprocessed_data)
    
    # Classificar t√≥picos
    topic_results = classify_topics(preprocessed_data)
    
    # Extrair entidades
    entity_results = extract_named_entities(preprocessed_data)
    
    # Agregar resultados
    insights = aggregate_results(sentiment_results, topic_results, entity_results)
    
    # Gerar visualiza√ß√µes
    create_visualizations(insights)
    
    # Configurar alertas
    alerts = configure_alerts(insights)
    
    # Exportar resultados para dashboard
    export_to_dashboard(insights, alerts)
    
    return insights, alerts
```

## üìä Visualiza√ß√µes e Dashboards

### Exemplo de Dashboard de Feedback

```mermaid
graph TD
    A[Dashboard Principal] --> B[Vis√£o Geral]
    A --> C[An√°lise Temporal]
    A --> D[An√°lise por Produto]
    A --> E[Alertas Ativos]
    
    B --> B1[Distribui√ß√£o de Sentimento]
    B --> B2[Principais T√≥picos]
    B --> B3[Problemas Recorrentes]
    
    C --> C1[Tend√™ncias de Sentimento]
    C --> C2[NPS ao Longo do Tempo]
    C --> C3[T√≥picos Emergentes]
    
    D --> D1[Compara√ß√£o de Produtos]
    D --> D2[Pontos Fortes/Fracos]
    D --> D3[Mapa de Calor de Atributos]
    
    E --> E1[Alertas de Sentimento]
    E --> E2[Problemas Cr√≠ticos]
    E --> E3[Oportunidades]
```

## üìà M√©tricas de Avalia√ß√£o

- **Acur√°cia do Sentimento**: Compara√ß√£o com avalia√ß√£o humana
- **Cobertura de T√≥picos**: % de feedback corretamente categorizado
- **Recall de Entidades**: % de men√ß√µes importantes identificadas
- **Tempo de Processamento**: Lat√™ncia entre recebimento e an√°lise
- **Efetividade de Alerta**: Taxa de falsos positivos/negativos
- **Impacto nos Neg√≥cios**: Melhoria em m√©tricas de produto ap√≥s a√ß√£o

## üåü Casos de Uso Espec√≠ficos

### Desenvolvimento de Produto

```mermaid
graph TD
    A[An√°lise de Feedback] --> B[Identifica√ß√£o de Bugs]
    A --> C[Prioriza√ß√£o de Features]
    A --> D[Valida√ß√£o de Mudan√ßas]
    
    B --> E[Tickets de Corre√ß√£o]
    C --> F[Roadmap de Produto]
    D --> G[M√©tricas de Sucesso]
```

### Monitoramento de Marca e Reputa√ß√£o

```mermaid
graph TD
    A[An√°lise de M√≠dias Sociais] --> B[Sentimento de Marca]
    A --> C[Detec√ß√£o de Crises]
    A --> D[Benchmark Competitivo]
    
    B --> E[Relat√≥rios de Reputa√ß√£o]
    C --> F[Protocolos de Mitiga√ß√£o]
    D --> G[Estrat√©gia Competitiva]
```

### Melhoria de Experi√™ncia do Cliente

```mermaid
graph TD
    A[An√°lise de Jornada] --> B[Pontos de Atrito]
    A --> C[Expectativas n√£o Atendidas]
    A --> D[Momentos de Encantamento]
    
    B --> E[Redesenho de Experi√™ncia]
    C --> F[Ajuste de Comunica√ß√£o]
    D --> G[Amplia√ß√£o de Cases de Sucesso]
```

## üîç Considera√ß√µes Importantes

### Privacidade e √âtica

- Anonimiza√ß√£o de dados pessoais antes da an√°lise
- Consentimento claro para uso de feedback em an√°lises
- Implementa√ß√£o de pol√≠ticas de reten√ß√£o de dados
- Transpar√™ncia sobre uso de feedback para melhorias

### Limita√ß√µes T√©cnicas

- Desafios com idiomas de baixos recursos
- Dificuldade com linguagem altamente espec√≠fica de dom√≠nio
- Interpreta√ß√£o incorreta de sarcasmo e express√µes idiom√°ticas
- Vi√©s em modelos pr√©-treinados

### Implementa√ß√£o Gradual

```mermaid
graph LR
    A[Piloto] --> B[An√°lise B√°sica]
    B --> C[An√°lise Avan√ßada]
    C --> D[Insights Automatizados]
    D --> E[A√ß√µes Automatizadas]
```

1. **Piloto**: Come√ßar com escopo limitado e validar com an√°lise manual
2. **An√°lise B√°sica**: Implementar sentimento e t√≥picos simples
3. **An√°lise Avan√ßada**: Adicionar entidades e rela√ß√µes complexas
4. **Insights Automatizados**: Gerar recomenda√ß√µes baseadas em padr√µes
5. **A√ß√µes Automatizadas**: Fechar o ciclo com a√ß√µes diretas baseadas em feedback

## üìà Resultados Esperados

- Redu√ß√£o de 70-80% no tempo para identificar problemas cr√≠ticos
- Aumento de 40-50% na capacidade de processamento de feedback
- Melhoria de 20-30% na precis√£o de categoriza√ß√£o de problemas
- Economia de 30-40% em recursos de an√°lise manual
- ROI significativo atrav√©s de corre√ß√µes mais r√°pidas e melhorias priorizadas

## üîó Integra√ß√£o com Outros Sistemas

- **CRM**: Enriquecer perfis de clientes com sentimentos e prefer√™ncias
- **Sistemas de Ticketing**: Criar e priorizar tickets automaticamente
- **Ferramentas de Product Management**: Alimentar decis√µes de roadmap
- **Business Intelligence**: Fornecer KPIs e m√©tricas sobre satisfa√ß√£o
- **Sistemas de Marketing**: Informar campanhas baseadas em sentimentos