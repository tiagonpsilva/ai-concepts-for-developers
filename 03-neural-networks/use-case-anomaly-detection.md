# ğŸ” Caso de Uso: DetecÃ§Ã£o de Anomalias em SÃ©ries Temporais

## ğŸ¯ Objetivo

Desenvolver um sistema baseado em redes neurais para identificar padrÃµes anormais em sÃ©ries temporais, permitindo a detecÃ§Ã£o proativa de falhas, fraudes, eventos incomuns ou comportamentos inesperados.

## ğŸ” Problema de NegÃ³cio

A detecÃ§Ã£o de anomalias em sÃ©ries temporais Ã© crucial em diversos setores, desde monitoramento de infraestrutura atÃ© seguranÃ§a cibernÃ©tica. MÃ©todos tradicionais estatÃ­sticos enfrentam dificuldades em:

- Capturar relaÃ§Ãµes temporais complexas
- Lidar com padrÃµes sazonais ou cÃ­clicos
- Identificar anomalias contextuais (normais em certas condiÃ§Ãµes, anormais em outras)
- Adaptar-se a novos padrÃµes sem reconfiguraÃ§Ã£o manual

Redes neurais, especialmente arquiteturas recorrentes e autoencoders, podem aprender representaÃ§Ãµes robustas de comportamentos normais e identificar desvios com maior precisÃ£o.

## ğŸ“Š Dados NecessÃ¡rios

- SÃ©ries temporais com mediÃ§Ãµes regulares (sensores, mÃ©tricas de sistema, dados financeiros)
- Metadados contextuais (informaÃ§Ãµes sobre ambiente, condiÃ§Ãµes de operaÃ§Ã£o)
- Dados histÃ³ricos com anomalias rotuladas (se disponÃ­veis)
- InformaÃ§Ãµes sobre manutenÃ§Ãµes, intervenÃ§Ãµes ou eventos especiais

## ğŸ› ï¸ Abordagem com Redes Neurais

```mermaid
graph TD
    A[Coleta de Dados] --> B[PrÃ©-processamento]
    B --> C[Feature Engineering]
    C --> D[Treinamento do Modelo]
    D --> E[DetecÃ§Ã£o de Anomalias]
    E --> F[PÃ³s-processamento]
    F --> G[Alertas e Dashboards]
    G -->|Feedback| H[AtualizaÃ§Ã£o do Modelo]
    H -->|Loop| D
```

### 1. Arquiteturas Neurais para DetecÃ§Ã£o de Anomalias

#### Autoencoders

```mermaid
graph LR
    A[Input] --> B[Encoder]
    B --> C[CÃ³digo Latente]
    C --> D[Decoder]
    D --> E[ReconstruÃ§Ã£o]
    E -->|ComparaÃ§Ã£o| A
    E -->|Erro de ReconstruÃ§Ã£o| F[Score de Anomalia]
```

Os autoencoders aprendem a reconstruir dados normais. Quando confrontados com anomalias, produzem erros de reconstruÃ§Ã£o elevados.

#### LSTM para PrevisÃ£o

```mermaid
graph TD
    A[SequÃªncia de Entrada] --> B[LSTM]
    B --> C[PrevisÃ£o]
    C -->|ComparaÃ§Ã£o| D[Valor Real]
    C -->|Erro de PrevisÃ£o| E[Score de Anomalia]
```

Modelos baseados em LSTM fazem previsÃµes de prÃ³ximos valores. Desvios significativos entre valores previstos e reais indicam anomalias.

#### Redes Neurais Variacionais (VAE)

```mermaid
graph LR
    A[Input] --> B[Encoder]
    B --> C[DistribuiÃ§Ã£o Latente]
    C -->|Amostragem| D[Ponto Latente]
    D --> E[Decoder]
    E --> F[ReconstruÃ§Ã£o]
    F -->|DivergÃªncia KL + Erro| G[Score de Anomalia]
```

VAEs adicionam um componente probabilÃ­stico, oferecendo robustez adicional em dados ruidosos.

## ğŸ’» Exemplo de ImplementaÃ§Ã£o

ImplementaÃ§Ã£o de um Autoencoder LSTM para detecÃ§Ã£o de anomalias em sÃ©ries temporais:

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import precision_recall_curve, auc
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input

# Carregar os dados de sÃ©rie temporal
df = pd.read_csv('sensor_data.csv', parse_dates=['timestamp'], index_col='timestamp')

# PrÃ©-processamento: normalizaÃ§Ã£o
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df.values)

# Preparar sequÃªncias para o modelo
def create_sequences(data, seq_length):
    sequences = []
    for i in range(len(data) - seq_length):
        seq = data[i:i + seq_length]
        sequences.append(seq)
    return np.array(sequences)

# ParÃ¢metros
seq_length = 24  # 24 horas, por exemplo
threshold_multiplier = 3  # Para definir o limiar de anomalia

# Criar sequÃªncias
sequences = create_sequences(scaled_data, seq_length)

# Dividir em treino e teste (assumindo que dados de treino sÃ£o "normais")
train_size = int(len(sequences) * 0.8)
train_data = sequences[:train_size]
test_data = sequences[train_size:]

# Construir o modelo Autoencoder LSTM
def build_lstm_autoencoder(input_shape):
    inputs = Input(shape=input_shape)
    
    # Encoder
    encoded = LSTM(64, activation='relu', return_sequences=False)(inputs)
    
    # RepresentaÃ§Ã£o latente
    latent_representation = RepeatVector(input_shape[0])(encoded)
    
    # Decoder
    decoded = LSTM(64, activation='relu', return_sequences=True)(latent_representation)
    outputs = TimeDistributed(Dense(input_shape[1]))(decoded)
    
    # Autoencoder completo
    autoencoder = Model(inputs, outputs)
    autoencoder.compile(optimizer='adam', loss='mse')
    
    return autoencoder

# Definir e treinar o modelo
input_shape = (seq_length, scaled_data.shape[1])
model = build_lstm_autoencoder(input_shape)
history = model.fit(
    train_data, train_data,
    epochs=50,
    batch_size=32,
    validation_split=0.1,
    verbose=1
)

# Calcular erros de reconstruÃ§Ã£o no conjunto de treino
train_predictions = model.predict(train_data)
train_errors = np.mean(np.square(train_data - train_predictions), axis=(1, 2))

# Definir limiar baseado na distribuiÃ§Ã£o de erros de treino
threshold = np.mean(train_errors) + threshold_multiplier * np.std(train_errors)

# FunÃ§Ã£o para detectar anomalias em novos dados
def detect_anomalies(new_data, model, threshold, scaler, seq_length):
    # PrÃ©-processamento dos novos dados
    scaled_new_data = scaler.transform(new_data)
    sequences = create_sequences(scaled_new_data, seq_length)
    
    # Fazer previsÃµes
    predictions = model.predict(sequences)
    
    # Calcular erros de reconstruÃ§Ã£o
    errors = np.mean(np.square(sequences - predictions), axis=(1, 2))
    
    # Marcar anomalias
    anomalies = errors > threshold
    
    # Mapear de volta para os timestamps originais
    anomaly_timestamps = []
    for i, is_anomaly in enumerate(anomalies):
        if is_anomaly:
            # O Ã­ndice i+seq_length corresponde ao Ãºltimo ponto da sequÃªncia
            anomaly_timestamps.append(i + seq_length)
    
    return anomaly_timestamps, errors

# Detectar anomalias no conjunto de teste
test_anomaly_indices, test_errors = detect_anomalies(
    df.values[train_size:], model, threshold, scaler, seq_length
)

# Visualizar resultados
plt.figure(figsize=(15, 7))
plt.plot(df.index[seq_length:], np.concatenate([train_errors, test_errors]), label='Erro de ReconstruÃ§Ã£o')
plt.axhline(y=threshold, color='r', linestyle='-', label='Limiar de Anomalia')
for idx in test_anomaly_indices:
    plt.axvline(x=df.index[train_size + idx], color='g', alpha=0.3)
plt.legend()
plt.title('DetecÃ§Ã£o de Anomalias com Autoencoder LSTM')
plt.show()
```

## ğŸ“ MÃ©todos de AvaliaÃ§Ã£o

- **PrecisÃ£o e Recall**: Fundamental quando anomalias conhecidas estÃ£o disponÃ­veis
- **AUC-ROC**: AvaliaÃ§Ã£o do poder discriminativo do modelo
- **Erros Tipo I e II**: Falsos positivos vs. falsos negativos
- **Tempo de DetecÃ§Ã£o**: Rapidez na identificaÃ§Ã£o de anomalias
- **Interpretabilidade**: Capacidade de explicar a razÃ£o da anomalia

## ğŸŒŸ AplicaÃ§Ãµes em Diferentes Setores

### IndÃºstria (IoT e Manufatura)

```mermaid
graph TD
    A[Sensores de MÃ¡quinas] --> B[PrÃ©-processamento]
    B --> C[Modelo LSTM]
    C --> D[DetecÃ§Ã£o de Anomalias]
    D --> E{Anomalia?}
    E -->|Sim| F[Alerta de ManutenÃ§Ã£o]
    E -->|NÃ£o| G[OperaÃ§Ã£o Normal]
```

Monitoramento de saÃºde de equipamentos, detecÃ§Ã£o precoce de falhas, manutenÃ§Ã£o preditiva.

### CiberseguranÃ§a

```mermaid
graph TD
    A[Logs de Rede] --> B[ExtraÃ§Ã£o de Features]
    B --> C[Modelo VAE/GAN]
    C --> D[Score de Anomalia]
    D --> E{Suspeito?}
    E -->|Sim| F[InvestigaÃ§Ã£o]
    E -->|NÃ£o| G[TrÃ¡fego Normal]
```

DetecÃ§Ã£o de intrusÃµes, identificaÃ§Ã£o de comportamentos suspeitos, prevenÃ§Ã£o de ataques.

### FinanÃ§as

```mermaid
graph TD
    A[TransaÃ§Ãµes] --> B[Feature Engineering]
    B --> C[Modelo HÃ­brido]
    C --> D[Score de Risco]
    D --> E{Fraudulento?}
    E -->|Sim| F[Bloqueio]
    E -->|Suspeito| G[VerificaÃ§Ã£o Adicional]
    E -->|NÃ£o| H[AprovaÃ§Ã£o]
```

DetecÃ§Ã£o de fraudes, identificaÃ§Ã£o de transaÃ§Ãµes suspeitas, anÃ¡lise de riscos.

## ğŸ“ˆ Resultados Esperados

- ReduÃ§Ã£o de 40-60% em falsos positivos comparado a mÃ©todos tradicionais
- DetecÃ§Ã£o precoce de falhas 2-5 dias antes de ocorrerem
- Aumento de 30-50% na eficiÃªncia operacional de times de monitoramento
- ReduÃ§Ã£o de 25-40% em custos de manutenÃ§Ã£o nÃ£o planejada

## ğŸ” Desafios e ConsideraÃ§Ãµes

- **DefiniÃ§Ã£o de "Normal"**: Estabelecer uma baseline robusta em sistemas complexos
- **Anomalias Evolutivas**: Adaptar-se a novos tipos de anomalias
- **Dados Desbalanceados**: Treinar com poucos exemplos de anomalias disponÃ­veis
- **LatÃªncia de DetecÃ§Ã£o**: Equilibrar rapidez e precisÃ£o
- **Interpretabilidade**: Explicar por que algo foi marcado como anomalia
- **Sazonalidade e TendÃªncias**: Distinguir padrÃµes normais de anomalias